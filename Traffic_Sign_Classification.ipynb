{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sratnaparkhi/Capstone-project/blob/main/Traffic_Sign_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZQGKN3d9POI"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2iWMvSm9Ruh"
      },
      "source": [
        "In this project, we will use Convolutional Neural Network to build train and test a traffic sign classification model. We will build this model using tensorflow and keras. It is a multiclass classification problem. This model can be used to make smarter cars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          }
        },
        "id": "wf7-EsX99P7J",
        "outputId": "0aa1c1ab-44e5-492e-8b10-f773758e2eb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-580d680f-4c4b-4993-83ac-f222a1d7b1a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-580d680f-4c4b-4993-83ac-f222a1d7b1a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run this cell and select the kaggle.json file downloaded from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q93aviRocggV"
      },
      "source": [
        "We will start by connecting to Kaggle using Kaggle API which can be downloaded from your Kaggle account's settings and uploading it here(upload box)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6t6UlzY9ZPH"
      },
      "outputs": [],
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgZNe-6idYTM"
      },
      "source": [
        "Installing kaggle api using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdN3ZFKS9bzc"
      },
      "outputs": [],
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle, so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTVvA3gck_p"
      },
      "source": [
        "Setting up Kaggle using Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEWoKy939e0S"
      },
      "outputs": [],
      "source": [
        "# Creating directory and changing the current working directory\n",
        "!mkdir traffic_sign_dataset\n",
        "%cd traffic_sign_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJKt8mPDcpV-"
      },
      "source": [
        "To store the data we will create a new directory and make it as current working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzGxQr3T9e_q"
      },
      "outputs": [],
      "source": [
        "# Searching for dataset\n",
        "!kaggle datasets list -s gtsrb-german-traffic-sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKrC4jXFcuBi"
      },
      "source": [
        "Searching Kaggle for the required dataset using search option(-s) with title 'dogbreedidfromcomp'. We can also use different search options like searching competitions, notebooks, kernels, datasets, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJdl3GIP9fCs"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset and coming out of directory\n",
        "!kaggle datasets download meowmeowmeowmeowmeow/gtsrb-german-traffic-sign  \n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jrsy575cx7e"
      },
      "source": [
        "After searching the data next step would be downloading the data into collab notebook using references found in search option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOHRCQHJ9zu0"
      },
      "outputs": [],
      "source": [
        "# Unzipping downloaded file and removing unusable file\n",
        "!unzip traffic_sign_dataset/gtsrb-german-traffic-sign.zip -d traffic_sign_dataset\n",
        "!rm traffic_sign_dataset/gtsrb-german-traffic-sign.zip\n",
        "!rm -rf traffic_sign_dataset/Meta\n",
        "!rm -rf traffic_sign_dataset/meta\n",
        "!rm -rf traffic_sign_dataset/test\n",
        "!rm -rf traffic_sign_dataset/train\n",
        "!rm traffic_sign_dataset/Meta.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5oG3Q8Ac9lA"
      },
      "source": [
        "We will unzip the data which is downloaded and remove the irrelevant files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnDWKmh39zx4"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-tswFNdrjj"
      },
      "source": [
        "Importing required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_ERdvte_YIw"
      },
      "outputs": [],
      "source": [
        "# Plotting 12 images to check dataset\n",
        "plt.figure(figsize=(12,12))\n",
        "path = \"traffic_sign_dataset/Test\"\n",
        "for i in range(1,17):\n",
        "    plt.subplot(4,4,i)\n",
        "    plt.tight_layout()\n",
        "    rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n",
        "    plt.imshow(rand_img)\n",
        "    plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image\n",
        "    plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDzMeI-9d5Db"
      },
      "source": [
        "Visualizing some images of traffic sign from the test dataset. we can see here that the dimension of images are uneven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaihvai8BTxH"
      },
      "outputs": [],
      "source": [
        "# As size of images are different we have to make them equal so we will take mean of dimanesions\n",
        "dim1 = []\n",
        "dim2 = []\n",
        "\n",
        "for i in range(0,43):\n",
        "    labels = 'traffic_sign_dataset/Train' + '/{0}'.format(i)\n",
        "    image_path = os.listdir(labels)\n",
        "    for x in image_path:\n",
        "        img = imread(labels + '/' + x)\n",
        "        dim1.append(img.shape[0])\n",
        "        dim2.append(img.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-4uIV2edAf"
      },
      "source": [
        "For further processing we will require the images of same dimension. So, we will start storing the dimension of all the images from training dataset from all 43 classes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k0kjKHqDYvZ"
      },
      "outputs": [],
      "source": [
        "#Printing mean dimension of images\n",
        "print(\"Dimension 1 Mean : \",np.mean(dim1), \" Dimension 2 Mean : \",np.mean(dim2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xm6X4AIfIdG"
      },
      "source": [
        "Now we will find out the mean value of both the dimensions and analyse them. Here, we can see that (50,50) is the average shape for all the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYlG6oahDsgn"
      },
      "outputs": [],
      "source": [
        "# Now we will reshape the images to (50,50)\n",
        "images = []\n",
        "label_id = []\n",
        "\n",
        "for i in range(43):\n",
        "    labels = 'traffic_sign_dataset/Train' + '/{0}'.format(i)\n",
        "    image_path = os.listdir(labels)\n",
        "    for x in image_path:\n",
        "        img = Image.open(labels + '/' + x)\n",
        "        img = img.resize((50,50))\n",
        "        img = np.array(img)\n",
        "        images.append(img)\n",
        "        label_id.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zr8Ip_8giBv"
      },
      "source": [
        "Now we will reshape the images into (50,50) and also store their label ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbY9MSaaEFeq"
      },
      "outputs": [],
      "source": [
        "#Converting images into numpy array\n",
        "images = np.array(images)\n",
        "#The pixel value of each image ranges between 0 and 255\n",
        "#Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\n",
        "images = images/255 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p04xcb7cg01H"
      },
      "source": [
        "Now we will convert all the images into numpy array and normalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spCgQYCMESBQ"
      },
      "outputs": [],
      "source": [
        "label_id = np.array(label_id)\n",
        "label_id.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQomtbYg-_0"
      },
      "source": [
        "Storing the label ids into numpy array and printing the shape. Here we can observe that their are 39209 label ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQZXYvNzEVkw"
      },
      "outputs": [],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WDpgwyMhNpV"
      },
      "source": [
        "Checking the shape of the images. Here we can see that their are 39209 images with a shape of (50,50,3.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WC2sIMmEWYU"
      },
      "outputs": [],
      "source": [
        "# Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_id).value_counts()\n",
        "label_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7k6aiXfhrjs"
      },
      "source": [
        "Now we will observe images per class for checking whether the data is balanced or not. From the result we can say that data is balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2hWQ3YIEc-o"
      },
      "outputs": [],
      "source": [
        "#Splitting the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(images, label_id , test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAoDpM03iqqI"
      },
      "source": [
        "The next step would be to split the data into training and validation with 80% of training data and 20% of validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdnFqZybEupr"
      },
      "outputs": [],
      "source": [
        "#keras has a built-in function for one-hot encoding.\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_val_cat = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfn9rGf1kGPv"
      },
      "source": [
        "Converting the classes column into categorical using to_categorical() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_d1-ckeE2aw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), input_shape = x_train.shape[1:], activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(43, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UdL6JTvkW8E"
      },
      "source": [
        "Defining the model architecture. In this we will define all the layers with their input shape kernel size, activation, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0EWaNciJry-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl_aHjtOk9tw"
      },
      "source": [
        "Compiling the model using metrics, optimizer and loss as required and printing out the summary of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocYgOv-0JsfT"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs = 10, batch_size = 128, validation_data = (x_val, y_val), verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoG9cFlhlMOC"
      },
      "source": [
        "Now we will fit the model and observe how our is getting trained on each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doO1VovGJ5i0"
      },
      "outputs": [],
      "source": [
        "evaluation = pd.DataFrame(model.history.history)\n",
        "evaluation[['accuracy', 'val_accuracy']].plot()\n",
        "evaluation[['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LKSAcQGl_mJ"
      },
      "source": [
        "Next we will visualize the accuracy and loss per epoch. For this we will store the model history in the pandas dataframe and plot them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixsgr0jlQTFP"
      },
      "outputs": [],
      "source": [
        "test_path = 'traffic_sign_dataset/Test'\n",
        "!rm traffic_sign_dataset/Test/GT-final_test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kokV342Nmlkk"
      },
      "source": [
        "Creating the variable which has path of test dataset. As we downloded the dataset we found out that their is a GT-final_test.csv file in the test images folder which cannot be processed. So, we will remove that file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TXtpJbTQXFU"
      },
      "outputs": [],
      "source": [
        "#defining a function that will scale images\n",
        "from PIL import Image\n",
        "\n",
        "def scaling(test_images, test_path):\n",
        "    images = []\n",
        "\n",
        "    image_path = test_images\n",
        "    \n",
        "    for x in image_path:\n",
        "        img = Image.open(test_path + '/' + x)\n",
        "        img = img.resize((50,50))\n",
        "        img = np.array(img)\n",
        "        images.append(img)\n",
        "\n",
        "    #Converting images into numpy array\n",
        "    images = np.array(images)\n",
        "    #The pixel value of each image ranges between 0 and 255\n",
        "    #Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\n",
        "    images = images/255\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfonPVJznMRB"
      },
      "source": [
        "Next step would we creating a function to resize the test images converting them into a numpy array and normalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0drYIKsmQcga"
      },
      "outputs": [],
      "source": [
        "test_images = scaling(sorted(os.listdir(test_path)),test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdn-LHM2nfx-"
      },
      "source": [
        "Calling the above created function on test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB0nhfiDQc6C"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('traffic_sign_dataset/Test.csv')\n",
        "y_test = test['ClassId'].values\n",
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSLIQkB5no2Q"
      },
      "source": [
        "Next we will read label ids from Test.csv and store the values of the class id in y_test variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4OjbwyGQjcw"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict_classes(test_images);\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu23-QJzoOFL"
      },
      "source": [
        "Now we will use the model to make predictions on our test images and save them in y_pred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diVVLWzvEGNu"
      },
      "outputs": [],
      "source": [
        "# Storing all lables\n",
        "all_lables = ['Speed limit (20km/h)','Speed limit (30km/h)','Speed limit (50km/h)','Speed limit (60km/h)',\n",
        "              'Speed limit (70km/h)','Speed limit (80km/h)','End of speed limit (80km/h)','Speed limit (100km/h)',\n",
        "              'Speed limit (120km/h)','No passing','No passing for vechiles over 3.5 metric tons',\n",
        "              'Right-of-way at the next intersection','Priority road','Yield','Stop','No vechiles',\n",
        "              'Vechiles over 3.5 metric tons prohibited','No entry','General caution','Dangerous curve to the left',\n",
        "              'Dangerous curve to the right','Double curve','Bumpy road','Slippery road','Road narrows on the right',\n",
        "              'Road work','Traffic signals','Pedestrians','Children crossing','Bicycles crossing','Beware of ice/snow',\n",
        "              'Wild animals crossing','End of all speed and passing limits','Turn right ahead','Turn left ahead',\n",
        "              'Ahead only','Go straight or right','Go straight or left','Keep right','Keep left','Roundabout mandatory',\n",
        "              'End of no passing','End of no passing by vechiles over 3.5 metric']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoULg2ysot7D"
      },
      "source": [
        "Storing the labels according to the image classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKCGS13aQp-P"
      },
      "outputs": [],
      "source": [
        "# Visualize test image\n",
        "img = Image.open(test_path + '/00001.png')\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JqaYFECo373"
      },
      "source": [
        "Let's visualize test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agT8igHnHNDj"
      },
      "outputs": [],
      "source": [
        "# Original label\n",
        "print(\"Original label : \",all_lables[y_test[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIyb3C-XpEGZ"
      },
      "source": [
        "Finding out original label for the image above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9YQO0jqIj8j"
      },
      "outputs": [],
      "source": [
        "# Predicted label\n",
        "print(\"Predicted label : \",all_lables[y_pred[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBItNkDZpMK0"
      },
      "source": [
        "Finding out the predicted label for the image above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwHeXF2OpWXi"
      },
      "source": [
        "## Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcTEz8_dpWaw"
      },
      "source": [
        "We started with downloading the dataset, preprocessing it, created the model and found out the predictions using the model. During preprocessing we found that this dataset has 43 classes. Model reached an accuracy of 95%+ in just 50 epochs, we can further optimize the model using hyper parameter tuning and reach a higher accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxAFt2A1qKWM"
      },
      "source": [
        "# Scope:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M__KNJw4qMKT"
      },
      "source": [
        "This model can be used in self driving cars which will enable them to automatically recognize traffic signs similarly the driver alert system inside cars will help and protect drivers by understanding the traffic signs around them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INSToaqiIyJv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Traffic_Sign_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}